* Convergence calculations
First, we need to determine an appropriate level of convergence for our calculations. I usually use the natural bulk configuration of a metal for these studies. For Pd, this is fcc.

** k-point convergence
First, we determine an appropriate /k/-point convergence. We will be performing many calculations, so a high level of accuracy is desirable, but not if the computational cost is too high. I use a high energy cutoff (400 eV) to make sure there are no effects from encut convergence to potentially skew the results.

#+label: fig-kpts
#+caption: /k/-point convergence metrics for a single atom unit cell of fcc Pd
#+attr_org: :width 600
[[./images/conv-kpt.png]]

Figure ref:fig-kpts shows that a Monkhorst-pack grid of roughly (14, 14, 14) /k/-points is sufficient to each 1 meV convergence.

#+BEGIN_SRC python :results silent
from ase.lattice.cubic import FaceCenteredCubic
import numpy as np
from jasp import *
import matplotlib.pyplot as plt
from ase.visualize import view
JASPRC['queue.walltime'] = '24:00:00'

# Define the atoms object of interest
atoms = FaceCenteredCubic('Pd',
                          directions=[[0, 1, 1],
                                      [1, 0, 1],
                                      [1, 1, 0]],
                          latticeconstant=3.939)

# Always a good idea to visualize your unit cell before starting
#view(atoms)

# We will sample a large range of k-points
kpts = np.linspace(6, 30, 13)

nrg, t, ibz = [], [], []
ready = True
for k in kpts:

    with jasp('DFT/structure=fcc/convergence=kpoints/kpoints={0}'.format(int(k)),
              xc='PBE',
              kpts=(int(k), int(k), int(k)),
              encut=400, # Choose a relatively large value
              ibrion=-1, # Perform a single-point calcuation
              atoms=atoms) as calc:
        try:
            atoms = calc.get_atoms()
            nrg += [atoms.get_potential_energy()]
            t += [calc.get_elapsed_time() / 60.0]
            ibz += [len(calc.read_ibz_kpoints())]
        except(VaspQueued, VaspSubmitted):
            ready = False

if ready:
    # Take all energies in reference to the last
    nrg = np.array(nrg) - nrg[-1]

    fig = plt.figure(figsize=(6, 4))
    ax1 = fig.add_subplot(111)
    ax1.plot(kpts, nrg, 'bo-')

    tol = 0.001
    ax1.plot([kpts.min(), kpts.max()], [tol, tol], 'k--')
    ax1.plot([kpts.min(), kpts.max()], [-tol, -tol], 'k--')

    ax1.set_xlim(kpts.min(), kpts.max())
    ax1.set_ylabel('Relative potential energy (eV)', color='b')
    ax1.tick_params(axis='y', colors='b')

    ax2 = ax1.twinx()

    ax2.plot(kpts, t, 'ro-')
    ax2.set_ylabel('Calculation time (min)', color='r')
    ax2.set_xlim(kpts.min(), kpts.max())
    ax2.tick_params(axis='y', colors='r')
    ax2.set_ylim(0, 160)

    ax3 = ax1.twiny()
    
    ax3.set_xticks([0./ 24, 4./24, 8./24, 12./24, 16./24, 20./24, 24./24])
    ax3.set_xticklabels([ibz[0], ibz[2], ibz[4], ibz[6], ibz[8], ibz[10], ibz[12],])
    ax3.set_xlabel('IBZ $k$-points (total)')

    ax1.set_xlabel('Monkhorst-pack grid $k$-point density (k, k, k)')
    plt.tight_layout()
    plt.savefig('images/conv-kpt.png')
#+END_SRC

** encut convergence
Next, we look at energy cutoff convergence. Similarly, /k/-point density is fixed at (16, 16, 16) for these calculations to ensure no effects from lack of convergence.

#+label: fig-encut
#+caption: Energy cutoff convergence metrics for a single atom unit cell of fcc Pd.
#+attr_org: :width 600
[[./images/conv-encut.png]]

In this case, Figure ref:fig-encut shows 350 eV energy cutoff is sufficient to achieve 1 meV convergence. Interestingly, the timing information suggests that 450 eV may be a better choice, or higher, but this is difficult to determine with a single run.

#+BEGIN_SRC python :results silent
from ase.lattice.cubic import FaceCenteredCubic
import numpy as np
from jasp import *
import matplotlib.pyplot as plt
from ase.visualize import view
JASPRC['queue.walltime'] = '24:00:00'

# Define the atoms object of interest
atoms = FaceCenteredCubic('Pd',
                          directions=[[0, 1, 1],
                                      [1, 0, 1],
                                      [1, 1, 0]],
                          latticeconstant=3.939)

# Always a good idea to visualize your unit cell before starting
#view(atoms)

# We will sample a large range of encut
encut = np.linspace(300, 800, (800-300)/23)

nrg, t = [], []
ready = True
for k in encut:

    with jasp('DFT/structure=fcc/convergence=encut/encut={0}'.format(int(k)),
              xc='PBE',
              kpts=(16, 16, 16), # Choose a relatively large value
              encut=k,
              ibrion=-1, # Perform a single-point calcuation
              atoms=atoms) as calc:
        try:
            atoms = calc.get_atoms()
            nrg += [atoms.get_potential_energy()]
            t += [calc.get_elapsed_time() / 60.0]
        except(VaspQueued, VaspSubmitted):
            ready = False

if ready:
    # Take all energies in reference to the last
    nrg = np.array(nrg) - nrg[-1]

    fig = plt.figure(figsize=(6, 4))
    ax1 = fig.add_subplot(111)
    ax1.plot(encut, nrg, 'bo-')

    tol = 0.001
    ax1.plot([encut.min(), encut.max()], [tol, tol], 'k--')
    ax1.plot([encut.min(), encut.max()], [-tol, -tol], 'k--')

    ax1.set_xlim(encut.min(), encut.max())
    ax1.set_ylabel('Relative potential energy (eV)', color='b')
    ax1.tick_params(axis='y', colors='b')

    ax2 = ax1.twinx()

    #ax2.plot(encut, t, 'ro-')
    ax2.barv(encut, t, facecolor='r', alpha=0.25)
    ax2.set_ylabel('Calculation time (min)', color='r')
    ax2.set_xlim(encut.min(), encut.max())
    ax2.tick_params(axis='y', colors='r')
    ax2.set_ylim(0, 160)

    ax1.set_xlabel('Energy cutoff (eV)')
    plt.tight_layout()
    plt.savefig('./images/conv-encut.png')
#+END_SRC

** ediff convergence
Finally, we look at the effects of electronic convergence criteria on total energy convergence. For this study, /k/-points are fixed at (16, 16, 16) and encut at 400 eV.

#+label: fig-ediff
#+caption: Electronic convergence criteria (ediff) convergence metrics for a single atom unit cell of fcc Pd.
#+attr_org: :width 600
[[./images/conv-ediff.png]]

Interestingly, Figure ref:fig-ediff shows that values less than 5e-3 eV (or 5 meV) have no effect on the convergence of the total energy. The calculation times suggest that the default of 1e-4 eV is a good choice.

#+BEGIN_SRC python :results silent
from ase.lattice.cubic import FaceCenteredCubic
import numpy as np
from jasp import *
import matplotlib.pyplot as plt
from ase.visualize import view
JASPRC['queue.walltime'] = '24:00:00'

# Define the atoms object of interest
atoms = FaceCenteredCubic('Pd',
                          directions=[[0, 1, 1],
                                      [1, 0, 1],
                                      [1, 1, 0]],
                          latticeconstant=3.939)

# Always a good idea to visualize your unit cell before starting
#view(atoms)

# We will sample a small range of ediff
ediff = np.array([1e-2, 5e-3, 1e-3, 5e-4, 1e-4, 5e-5, 1e-5, 5e-6, 1e-6])

nrg, t = [], []
ready = True
for k in ediff:

    with jasp('DFT/structure=fcc/convergence=ediff/ediff={0:1.6f}'.format(k),
              xc='PBE',
              kpts=(16, 16, 16), # Choose a relatively large value
              encut=400,
              ediff=k,
              ibrion=-1, # Perform a single-point calcuation
              atoms=atoms) as calc:
        try:
            atoms = calc.get_atoms()
            nrg += [atoms.get_potential_energy()]
            t += [calc.get_elapsed_time() / 60.0]
        except(VaspQueued, VaspSubmitted):
            ready = False

if ready:
    # Take all energies in reference to the last
    nrg = np.array(nrg) - nrg[-1]

    fig = plt.figure(figsize=(6, 4))
    ax1 = fig.add_subplot(111)
    ax1.semilogx(ediff, nrg, 'bo-')

    tol = 0.001
    ax1.plot([ediff.min(), ediff.max()], [tol, tol], 'k--')
    ax1.plot([ediff.min(), ediff.max()], [-tol, -tol], 'k--')

    ax1.set_xlim(ediff.min(), ediff.max())
    ax1.set_ylabel('Relative potential energy (eV)', color='b')
    ax1.tick_params(axis='y', colors='b')
    ax1.invert_xaxis()

    ax2 = ax1.twinx()

    ax2.semilogx(ediff, t, 'ro-')
    ax2.set_ylabel('Calculation time (min)', color='r')
    ax2.set_xlim(ediff.min(), ediff.max())
    ax2.tick_params(axis='y', colors='r')
    ax2.invert_xaxis()
    ax2.set_ylim(0, 160)

    ax1.set_xlabel('Electronic convergence criteria (eV)')
    plt.tight_layout()
    plt.savefig('./images/conv-ediff.png')
#+END_SRC

* Equation of state
Next we use the convergence criteria to calculate Pd bulk fcc EOS at the desired level of accuracy. I have chosen (14, 14, 14) /k/-points, 400 eV encut, and 1e-4 eV ediff (default setting). We will need a good sized sample to fit the neural network. I have chosen a fine grid of 71 points about the expected minimum in energy, and 29 additional points to span the space leading to ``infinite'' separation. Figure ref:fig-eos shows the resulting fit. The code block also generates an ASE database, which we will use from this point on for easy access to the data. It is attached here: \attachfile{data.db}{(double-click to open)}.

#+label: fig-eos
#+caption: Equation of state for fcc Pd as calculated from DFT.
#+attr_org: :width 600
[[./images/eos.png]]

#+BEGIN_SRC python :results silent
from ase.lattice.cubic import FaceCenteredCubic
import numpy as np
from jasp import *
import matplotlib.pyplot as plt
from ase.utils.eos import EquationOfState
from ase.units import kJ
JASPRC['queue.walltime'] = '24:00:00'

# Functions produced by Jacob Boes for work in computational catalysis
# These are freely available at: https://github.com/jboes/jbtools.git
import jbtools.gilgamesh as jb

# Fraction of equilibrium lattice constant to be calculated
factor = np.append(np.linspace(0.85, 1.2, 71),
                   np.linspace(1.23, 2.07, 29))

nrg, vol, t = [], [], []
ready = True
for x in factor:

    atoms = FaceCenteredCubic('Pd',
                              directions=[[0, 1, 1],
                                          [1, 0, 1],
                                          [1, 1, 0]],
                              latticeconstant=3.939)

    delta = np.array([[x, 0., 0.],
                      [0., x, 0.],
                      [0., 0., x]])
    atoms.set_cell(np.dot(atoms.get_cell(), delta),
                   scale_atoms=True)

    with jasp('DFT/structure=fcc/convergence=None/factor={0:1.3f}'.format(x),
              xc='PBE',
              kpts=(14, 14, 14), # Choose an appropriate value
              encut=400,
              ibrion=-1,
              atoms=atoms) as calc:
        try:
            atoms = calc.get_atoms()
            nrg += [atoms.get_potential_energy()]
            vol += [atoms.get_volume()]
            t += [calc.get_elapsed_time() / 60.0]
        except(VaspQueued, VaspSubmitted):
            ready = False

if ready:
    # Here we collect the data to an ASE database
    # for easy future manipulation
    jb.write_database('DFT/structure=fcc/convergence=None/')

    # We will use only the energies \pm 15 $\AA^{3}$ about 
    # the minimum energy for the figure.
    min_nrg = vol[nrg.index(min(nrg))]
    ind = (np.array(vol) > min_nrg - 15) & (np.array(vol) < min_nrg + 15)
    vol = np.array(vol)[ind]
    nrg = np.array(nrg)[ind]
    t = np.array(t)[ind]

    # Fit the data to SJEOS
    eos = EquationOfState(vol, nrg)
    v0, e0, B, fit = eos.fit()

    x = np.linspace(vol.min(), vol.max(), 250)

    fig = plt.figure(figsize=(6, 4))
    ax1 = fig.add_subplot(111)
    ax1.scatter(vol, nrg, color='b')
    ax1.plot(x, fit(x**-(1.0 / 3)), 'k-')

    ax1.set_xlim(vol.min(), vol.max())
    ax1.set_ylabel('Potential energy (eV)', color='b')
    ax1.tick_params(axis='y', colors='b')

    ax1.text(vol.max() - 6, nrg.max(),
             'V$_{0}$={1:1.1f}'.format('{min}', v0),
             va='center', ha='left')
    ax1.text(vol.max() - 6, nrg.max() - 0.3,
             'E$_{0}$={1:1.3f}'.format('{min}', e0),
             va='center', ha='left')
    ax1.text(vol.max() - 6, nrg.max() - 0.6,
             'B={0:1.0f}'.format(B  / kJ * 1.0e24),
             va='center', ha='left')

    ax2 = ax1.twinx()

    ax2.scatter(vol, t, color='r')
    ax2.set_ylabel('Calculation time (min)', color='r')
    ax2.set_xlim(vol.min(), vol.max())
    ax2.tick_params(axis='y', colors='r')
    ax2.set_ylim(0, 480)

    ax1.set_xlabel('Volume ($\AA^{3}$/atom)')
    plt.tight_layout()
    plt.savefig('./images/eos.png')
#+END_SRC

* Neural network
To train a neural network we will be using AMP (https://bitbucket.org/andrewpeterson/amp), a software package developed by the Peterson group at Brown University.

Before we begin creating out neural network, we need to separate about 10% of out data into a validation set. This will be useful later, when determining whether over fitting has occurred. There is functionality for this in AMP, but it does not provide with as much control as the following code.

#+BEGIN_SRC python :results silent
from ase.db import connect
import os
import random
import numpy as np

db = connect('data.db')

n = db.count()
n_train = int(round(n * 0.9))

n_ids =  np.array(range(n)) + 1

# This will sudo-randomly select 10% of the calculations
# Which is useful for reproducing our results.
random.seed(256)
train_samples = random.sample(n_ids, n_train)
valid_samples = set(n_ids) - set(train_samples)

db.update(list(train_samples), train_set=True)
db.update(list(valid_samples), train_set=False)

db0 = connect('train.db')

for d in db.select(['train_set=True']):
    db0.write(d, key_value_pairs=d.key_value_pairs)
#+END_SRC

Now we have sudo-randomly labeled 10% of our calculations for validation, and the rest are waiting to be trained in the new train.db file. This file is also attached: \attachfile{train.db}{(double-click to open)}.

** Training neural networks
For all of out neural networks, we will be using the Behler-Parenello (BP) framework for distinguishing between geometries of atoms. Little to no work is published on how to systematically chose an appropriate number of variables for your BP framework, so we simply use the default settings in AMP for now. However, it is worth mentioning that a single G1 type variable (simplest possible descriptor) could be used to describe the fcc EOS, if that is all we are interested in.

We also need to define a cutoff radius for our system which will determine the maximum distance that the BP framework considers atoms to be interacting. 6 $\AA$ is a typical value used in the literature for metals with no appreciable long range interactions, which we will be using here.

Finally, it is also often desirable to have multiple neural networks which are trained to the same level of accuracy, but with different frameworks. These frameworks are determined by the number of nodes and hidden layers used. In general, we want the smallest number of nodes and layers possible to avoid the possibility of over fitting. However, too small a framework will be too rigid to properly fit complex potential energy surfaces.

These jobs can be run locally:

#+BEGIN_SRC python :results silent
from amp import Amp
from amp.descriptor import *
from amp.regression import *
import os

for n in [2, 3]:
    label = '{0}-{0}'.format(n)
    wd = os.path.join(os.getcwd(), 'networks/' + label)

    if not os.path.exists(wd):
        os.makedirs(wd)

    calc = Amp(label="./networks/{0}/".format(label),
               descriptor=Behler(cutoff=6.0),
               regression=NeuralNetwork(hiddenlayers=(2, '{0}'.format(n))))

    calc.train("./train.db", # The training data
               cores=1,
               global_search=None, # not found the simulated annealing feature useful
               extend_variables=False) # feature does not work properly and will crash
#+END_SRC

We can also submit them to the queue on Gilgamesh:

#+BEGIN_SRC python
import os
import subprocess [[
]] 
import time

home = os.getcwd()

# We will try an iteration for 2 and 3 nodes with 2 hidden layers.
for n in [2, 3]:

    label = '{0}-{0}'.format(n)
    wd = os.path.join(home, 'networks/' + label)

    if not os.path.exists(wd):
        os.makedirs(wd)
    os.chdir(wd)

    run_amp = '''#!/usr/bin/env python
from amp import Amp
from amp.descriptor import *
from amp.regression import *

calc = Amp(label="./",
           descriptor=Behler(cutoff=6.0),
           regression=NeuralNetwork(hiddenlayers=(2, {0})))

calc.train("../../train.db", # The training data
           cores=1,
           global_search=None, # not found the simulated annealing feature useful
           extend_variables=False) # feature does not work properly and will crash
'''.format(n)

    cmd = '''#!/bin/bash
#PBS -N {0}
#PBS -l nodes=1:ppn=1
#PBS -l walltime=24:00:00
#PBS -l mem=2GB
#PBS -joe
cd $PBS_O_WORKDIR
./submit.py
#end'''.format(wd)

    with open('submit.py', 'w') as f:
        f.write(run_amp)
    os.chmod('submit.py', 0777)

    with open('submit.sh', 'w') as f:
        f.write(cmd)

    subprocess.call(['qsub', 'submit.sh'])
    time.sleep(5)
    os.unlink('submit.sh')
    os.chdir(wd)
#+END_SRC

#+RESULTS:
: 1305344.gilgamesh.cheme.cmu.edu
: 1305345.gilgamesh.cheme.cmu.edu

Once the calculations finish we can check their convergence using the code below. These are trivial networks to train, so convergence should not be an issue. If there is a problem, restart the calculation to try again. This can be a difficult and time consuming part of the process for more complex system. 

#+BEGIN_SRC python :results raw
import os
import json

print('|Hidden layers|Iteration|Time|Cost Function|Energy RMSE|Force RMSE|')
print('|-')

for r, d, f in os.walk('networks'):
    if 'train-log.txt' in f:
        with open(os.path.join(r, 'train-log.txt'), 'r') as fi:
            v = fi.readlines()[-3].split()

    if 'trained-parameters.json' in f:
        with open(os.path.join(r, 'trained-parameters.json'), 'r') as fi:
            p = json.load(fi)
        n = p['hiddenlayers']
        print('|{0}|{1}|{2}|{3}|{4}|{5}|'.format(n, v[0], v[1], v[2], v[3], v[4]))
#+END_SRC

#+RESULTS:
| Hidden layers   | Iteration | Time                | Cost Function | Energy RMSE | Force RMSE |
|-----------------+-----------+---------------------+---------------+-------------+------------|
| {u'Pd': [2, 2]} |       497 | 2015-11-18T15:59:22 |     8.921e-05 |   9.956e-04 |  0.000e+00 |
| {u'Pd': [2, 3]} |       266 | 2015-11-18T15:59:34 |     8.967e-05 |   9.982e-04 |  0.000e+00 |

The single atom unit cell enforces perfect symmetry. This results in cancellation of forces on the atom in the unit cell. Hence, force RMSE = 0.0, which makes for fast training, but less information to train too.

** Validation of the network
Now we need to validate our results to ensure that no over fitting has occurred. First, we will look at the residuals to the training and validation data. Then we will see if the neural networks perform well for their intended purpose. For ease of access, we will add the neural network energy predictions to the database for each structure.

#+BEGIN_SRC python :result silent
from ase.db import connect
from amp import Amp

db = connect('data.db')

calc2 = Amp('networks/2-2/')
calc3 = Amp('networks/3-3/')

for d in db.select():
    atoms = db.get_atoms(d.id)
    atoms.set_calculator(calc2)
    nrg2 = atoms.get_potential_energy()

    atoms.set_calculator(calc3)
    nrg3 = atoms.get_potential_energy()

    db.update(d.id, NN2=nrg2, NN3=nrg3)
#+END_SRC

*** Analysis of residuals
First we look at the residual errors of all the data in the database for each of our frameworks shown in Figure ref:fig-residuals-NN2 and ref:fig-residuals-NN3. For both fits, the validation set has lower RMSE than the training set. This is a good indication that neither has been over fit, which we can also observe for this simple example, since the validation points follow the same trends observed for the training set data. This is also a good example of how adding additional, unnecessary elements to the framework leads to lower overall fitting accuracy for.

#+label: fig-residuals-NN2
#+caption: Residual errors to the 2-2 framework neural network.
#+attr_org: :width 600
[[./images/residuals-NN2.png]]

#+label: fig-residuals-NN3
#+caption: Residual errors to the 3-3 framework neural network.
#+attr_org: :width 600
[[./images/residuals-NN3.png]]

#+BEGIN_SRC python :results silent
import numpy as np
import matplotlib.pyplot as plt
from ase.db import connect
from amp import Amp
import os

db = connect('data.db')

for n in [2, 3]:

    Qe, Ne, vol, ind = [], [], [], []
    for d in db.select():

        Qe += [d.energy]
        vol += [d.volume]

        Ne += [d['NN{0}'.format(n)]]
        ind += [d.train_set]

    res = np.array(Ne) - np.array(Qe)
    mask = np.array(ind)
    valid = np.ma.masked_array(res, mask)
    train = np.ma.masked_array(res, ~mask)
    vRMSE = np.sqrt(np.sum(valid ** 2)/ len(valid))
    tRMSE = np.sqrt(np.sum(train ** 2)/ len(train))

    plt.figure(figsize=(6, 4))

    plt.text(60, 0.0085, 
             'Trained RMSE: {0:1.2f} meV/atom'.format(tRMSE * 1000),
             color='b', ha='left')
    plt.text(60, 0.0070, 
             'Validation RMSE: {0:1.2f} meV/atom'.format(vRMSE * 1000),
             color='r', ha='left')

    plt.scatter(vol, train, color='b')
    plt.scatter(vol, valid, color='r')
    plt.plot([min(vol), max(vol)], [0, 0], 'k--')
    plt.xlim(min(vol), max(vol))
    plt.ylim(-0.01, 0.01)
    plt.xlabel('Volume ($\AA^{3}$/atom)')
    plt.ylabel('Residual error (eV/atom)')
    plt.tight_layout()
    plt.savefig('./images/residuals-NN{0}.png'.format(n))
#+END_SRC

*** Recreate the equation of state
Next, we recreate the equation of state using both of the neural networks and the same methodology as with DFT. The results are shown in Figures ref:fig-eos-NN2 and ref:fig-eos-NN3 for the 2-2 and 3-3 frameworks, respectively.

#+label: fig-eos-NN2
#+caption: Equation of state for fcc Pd as calculated from a neural network with 2-2 framework.
#+attr_org: :width 600
[[./images/eos-NN2.png]]

#+label: fig-eos-NN3
#+caption: Equation of state for fcc Pd as calculated from a neural network with 3-3 framework.
#+attr_org: :width 600
[[./images/eos-NN3.png]]

Each neural network creats are an excellent fit to the DFT data, and we see that the calculation speed has improved by up to 6 orders of magnitude in the most extreme cases. For this application the choice of framework seems to have little effect on the equation of state produced.

#+BEGIN_SRC python :results silent
import numpy as np
import matplotlib.pyplot as plt
from ase.utils.eos import EquationOfState
from ase.db import connect
from amp import Amp
from ase.visualize import view
import os
import json
import time
from ase.units import kJ

db = connect('data.db')

for r, d, f in os.walk('networks'):
    if 'trained-parameters.json' in f:
        calc = Amp(load=r + '/')

        with open(os.path.join(r, 'trained-parameters.json'), 'r') as fi:
            p = json.load(fi)
        n = p['hiddenlayers'].values()[0]

        nrg, vol, t = [], [], []
        for d in db.select():
            atoms = db.get_atoms(d.id)
            atoms.set_calculator(calc)

            time1 = time.time()
            energy = atoms.get_potential_energy()
            time2 = time.time()

            nrg += [energy]
            vol += [d.volume]
            t += [(time2 - time1) * 1000]

        min_nrg = vol[nrg.index(min(nrg))]
        ind = (np.array(vol) > min_nrg - 15) & (np.array(vol) < min_nrg + 15)
        vol = np.array(vol)[ind]
        nrg = np.array(nrg)[ind]
        t = np.array(t)[ind]

        # Fit the data to SJEOS
        eos = EquationOfState(vol, nrg)
        v0, e0, B, fit = eos.fit()

        x = np.linspace(vol.min(), vol.max(), 250)

        fig = plt.figure(figsize=(6, 4))
        ax1 = fig.add_subplot(111)
        ax1.scatter(vol, nrg, color='b')
        ax1.plot(x, fit(x**-(1.0 / 3)), 'k-')

        ax1.set_xlim(vol.min(), vol.max())
        ax1.set_ylabel('Potential energy (eV)', color='b')
        ax1.tick_params(axis='y', colors='b')

        ax1.text(vol.max() - 6, nrg.max(),
                 'V$_{0}$={1:1.1f}'.format('{min}', v0),
                 va='center', ha='left')
        ax1.text(vol.max() - 6, nrg.max() - 0.3,
                 'E$_{0}$={1:1.3f}'.format('{min}', e0),
                 va='center', ha='left')
        ax1.text(vol.max() - 6, nrg.max() - 0.6,
                 'B={0:1.0f}'.format(B  / kJ * 1.0e24),
                 va='center', ha='left')

        ax2 = ax1.twinx()

        ax2.scatter(vol, t, color='r')
        ax2.set_ylabel('Calculation time (milliseconds)', color='r')
        ax2.set_xlim(vol.min(), vol.max())
        ax2.tick_params(axis='y', colors='r')
        ax2.set_ylim(0, 40)

        ax1.set_xlabel('Volume ($\AA^{3}$/atom)')
        plt.tight_layout()
        plt.savefig('./images/eos-NN{0}.png'.format(n[-1]))
#+END_SRC

** Applications
Now we take a look at some common applications. 

*** Geometry optimization
#+BEGIN_SRC python
from amp import Amp
import numpy as np
from ase.lattice.cubic import FaceCenteredCubic
import matplotlib.pyplot as plt
import collections

D = {}
for calc in ['networks/2-2/',
             'networks/3-3/']:

    D[calc[-2]] = collections.OrderedDict()
    for x in np.linspace(0.60, 2.5, 1000.):

        atoms = FaceCenteredCubic('Pd',
                                  directions=[[0, 1, 1],
                                              [1, 0, 1],
                                              [1, 1, 0]],
                                  latticeconstant=3.939)

        delta = np.array([[x, 0., 0.],
                          [0., x, 0.],
                          [0., 0., x]])
        atoms.set_cell(np.dot(atoms.get_cell(), delta),
                       scale_atoms=True)

        atoms.set_calculator(Amp(calc))

        D[calc[-2]][x] = atoms.get_potential_energy()

res = abs(np.array(D['3'].values()) - np.array(D['2'].values()))

#plt.plot(D['2'].keys(), res)
#plt.show()

plt.plot(D['2'].keys(), D['2'].values(), 'b')
plt.plot(D['3'].keys(), D['3'].values(), 'r')
plt.show()
#+END_SRC

#+RESULTS:

*** Larger structures
#+BEGIN_SRC python
from amp import Amp
import numpy as np
from ase.lattice.cubic import FaceCenteredCubic
import matplotlib.pyplot as plt
from ase.visualize import view
from ase.optimize import BFGS

for calc in ['networks/2-2/',
             'networks/3-3/']:
    atoms = FaceCenteredCubic('Pd',
                              directions=[[0, 1, 1],
                                          [1, 0, 1],
                                          [1, 1, 0]],
                              latticeconstant=3.939)
    atoms.set_calculator(Amp(calc))
    atoms *= (3, 3, 3)

    nrg0 = atoms.get_potential_energy()

    del atoms[0]
    dyn = BFGS(atoms)
    dyn.run(fmax=0.05)

    nrg1 = atoms.get_potential_energy()
    fw = calc.split('/')[-2]
    ve = nrg1 - (26/27.)*nrg0

    print 'Vacancy formation energy with {0} framework NN: {1:1.3f} eV'.format(fw, ve)

#+END_SRC

#+RESULTS:
#+begin_example
BFGS:   0  23:22:14     -131.319326       0.6402
BFGS:   1  23:22:19     -131.359079       0.4868
BFGS:   2  23:22:24     -131.407465       0.1290
BFGS:   3  23:22:29     -131.408432       0.1178
BFGS:   4  23:22:34     -131.409158       0.0511
BFGS:   5  23:22:39     -131.406953       0.0411
Vacancy formation energy with 2-2 framework NN: 4.170
BFGS:   0  23:22:44     -135.182786       0.0558
BFGS:   1  23:22:49     -135.182910       0.0554
BFGS:   2  23:22:54     -135.183387       0.0320
Vacancy formation energy with 3-3 framework NN: 0.411
#+end_example

*** Molecular dynamics
#+BEGIN_SRC python :results silent
from __future__ import print_function
from ase.lattice.cubic import FaceCenteredCubic
from ase.md.langevin import Langevin
from ase.io.trajectory import Trajectory
from ase import units
from amp import Amp

# Set up a crystal
atoms = FaceCenteredCubic('Pd',
                          directions=[[0, 1, 1],
                                      [1, 0, 1],
                                      [1, 1, 0]],
                          latticeconstant=3.939,
                          size=(5, 5, 5))

# Describe the interatomic interactions with the Effective Medium Theory
atoms.set_calculator(Amp('networks/2-2/'))

# We want to run MD with constant energy using the Langevin algorithm
# with a time step of 5 fs, the temperature T and the friction
# coefficient to 0.02 atomic units.
dyn = Langevin(atoms, 5 * units.fs, 800 * units.kB, 0.002)


def printenergy(a=atoms):  # store a reference to atoms in the definition.
    """Function to print the potential, kinetic and total energy."""
    epot = a.get_potential_energy() / len(a)
    ekin = a.get_kinetic_energy() / len(a)
    
dyn.attach(printenergy, interval=1)

# We also want to save the positions of all atoms after every time step.
traj = Trajectory('MD.traj', 'w', atoms)
dyn.attach(traj.write, interval=1)

# Now run the dynamics
printenergy()
dyn.run(1000)
#+END_SRC

#+BEGIN_SRC python
from ase.io.trajectory import Trajectory
from ase.visualize import view

traj = Trajectory('MD.traj', 'r')

view(traj)
#+END_SRC
